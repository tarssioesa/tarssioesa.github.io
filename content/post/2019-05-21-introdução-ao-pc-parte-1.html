---
title: 'Introdução ao PC: Parte 1.'
author: Tarssio Barreto
date: '2019-05-21'
slug: introdução-ao-pc-parte-1
categories: []
tags: []
keywords:
  - tech
---



<div style="text-align: justify">

<div id="pca" class="section level2">
<h2>PCA</h2>
<p>De forma muito simples, o PCA tem as seguintes objetivos:</p>
<ol style="list-style-type: lower-alpha">
<li><p>Reduzir a dimensão dos dados em análise, visando eliminar sobreposições, a partir da combinação linear das variáveis originais.</p></li>
<li><p>Geometricamente, o objetivo do PCA é rotacionar o eixo de um espaço com p dimensões para uma nova posição, na qual os PCs são ordenados pela variância e a covariância entre cada par dos novos eixos é 0.</p></li>
<li><p>Esta técnica é comumente utilizada para visualização dos dados, regressão (PCR, PLS) e estudo de padrões (inclusive em imagens e textos).</p></li>
</ol>
<p>O passo-a-passo para criar o PCA é:</p>
<ol style="list-style-type: decimal">
<li><p>Definir a matriz de dados;</p></li>
<li><p>Calcular o vetor médio dos dados;</p></li>
<li><p>Subtrair a média de todos os itens;</p></li>
<li><p>Calcular a matriz de covâriancia;</p></li>
<li><p>Calcular autovalores e autovetores</p></li>
</ol>
</div>
<div id="pacotes-que-serao-utilizados" class="section level2">
<h2>Pacotes que serão utilizados:</h2>
<pre class="r"><code>#install.packages(&quot;pacman&quot;)
library(pacman)


p_load(caret, tidyverse, factoextra, epubr, tm, lexiconPT, broom, tidytext, widyr, irlba, 
       Rtsne,plotly)</code></pre>
<div id="realizando-o-pca-e-analisando-os-resultados" class="section level3">
<h3>Realizando o PCA e analisando os resultados</h3>
<div id="carregando-os-dados" class="section level4">
<h4>Carregando os dados:</h4>
<pre class="r"><code>dados &lt;- load(&quot;C:/Users/tarss/Desktop/SER/CURO_SER/data_041218_1138.RData&quot;)

dados &lt;- features_atual %&gt;% 
  group_by(categoria) %&gt;% 
  dplyr::filter(categoria %in% c(&quot;Torneira Interna&quot;, &quot;Bacia&quot;)) %&gt;% 
  dplyr::sample_n(1000)

dados$categoria &lt;- forcats::fct_drop(dados$categoria)


x &lt;- dados[,c(2:9)]</code></pre>
</div>
<div id="realizaremos-primeiro-o-pca-atraves-do-passo-a-passo-a-seguir" class="section level4">
<h4>Realizaremos, primeiro, o PCA através do passo-a-passo a seguir:</h4>
<ol style="list-style-type: decimal">
<li>Escalonando os dados:</li>
</ol>
<pre class="r"><code>x1 &lt;- scale(x)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Cálculo da covariância:</li>
</ol>
<pre class="r"><code>covariancia &lt;- cov(x1)

covariancia</code></pre>
<pre><code>##           duracao      nmoda    volume   inercia       moda     media
## duracao 1.0000000 0.92469359 0.7980497 0.2515225 0.15959878 0.1581550
## nmoda   0.9246936 1.00000000 0.6963917 0.3696323 0.07656319 0.0783363
## volume  0.7980497 0.69639167 1.0000000 0.3785107 0.55079672 0.5686573
## inercia 0.2515225 0.36963226 0.3785107 1.0000000 0.25295903 0.2516045
## moda    0.1595988 0.07656319 0.5507967 0.2529590 1.00000000 0.9074001
## media   0.1581550 0.07833630 0.5686573 0.2516045 0.90740014 1.0000000
## pico    0.2394809 0.10856376 0.5734895 0.1447658 0.80037668 0.8881444
## mediana 0.1668339 0.08862613 0.5801924 0.2863054 0.92883526 0.9702725
##              pico    mediana
## duracao 0.2394809 0.16683390
## nmoda   0.1085638 0.08862613
## volume  0.5734895 0.58019241
## inercia 0.1447658 0.28630543
## moda    0.8003767 0.92883526
## media   0.8881444 0.97027251
## pico    1.0000000 0.84267406
## mediana 0.8426741 1.00000000</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Autovetores e valores:</li>
</ol>
<pre class="r"><code>auto &lt;- eigen(covariancia)

auto$vectors # Autovetores</code></pre>
<pre><code>##            [,1]       [,2]        [,3]         [,4]        [,5]
## [1,] -0.2478093  0.5427337  0.25508083 -0.022880586 -0.06238973
## [2,] -0.2086872  0.5815919  0.06605807  0.111931814 -0.54715426
## [3,] -0.3946802  0.2965938  0.11920411  0.024446559  0.80044844
## [4,] -0.1966569  0.1933099 -0.93770175 -0.169647198  0.01961605
## [5,] -0.4129991 -0.2517535 -0.01369989  0.533407465 -0.09932880
## [6,] -0.4267455 -0.2631534  0.01070654 -0.003772862 -0.14048445
## [7,] -0.4057479 -0.2143878  0.18851863 -0.782874738 -0.14488542
## [8,] -0.4281150 -0.2515207 -0.03513275  0.245233214 -0.07094631
##             [,6]         [,7]        [,8]
## [1,] -0.15842994  0.725185516  0.15347425
## [2,]  0.14315979 -0.516057049 -0.12296633
## [3,]  0.07532313 -0.307250629 -0.02565466
## [4,] -0.08069840  0.091015866  0.02667747
## [5,] -0.67128726 -0.106825497  0.09714031
## [6,]  0.48212058 -0.008611709  0.70445679
## [7,] -0.28200152 -0.107278505 -0.17014429
## [8,]  0.42382510  0.286547949 -0.65215827</code></pre>
<pre class="r"><code>auto$values # Autovalores</code></pre>
<pre><code>## [1] 4.46802448 2.19397440 0.83986758 0.19992217 0.14766633 0.08804701
## [7] 0.04052160 0.02197642</code></pre>
</div>
<div id="exploraremos-agora-brevemente-alguns-opcoes-de-projecao-do-pca" class="section level4">
<h4>Exploraremos agora, brevemente, alguns opções de projeção do PCA:</h4>
<p>Usaremos para isto o pacote <code>factoextra</code>. Primeiramente, vamos construir nosso objeto <code>pca</code></p>
<pre class="r"><code>x_pca &lt;- prcomp(x, scale = TRUE)

summary(x_pca)</code></pre>
<pre><code>## Importance of components:
##                           PC1    PC2    PC3     PC4     PC5     PC6
## Standard deviation     2.1138 1.4812 0.9164 0.44713 0.38427 0.29673
## Proportion of Variance 0.5585 0.2742 0.1050 0.02499 0.01846 0.01101
## Cumulative Proportion  0.5585 0.8327 0.9377 0.96272 0.98118 0.99219
##                            PC7     PC8
## Standard deviation     0.20130 0.14824
## Proportion of Variance 0.00507 0.00275
## Cumulative Proportion  0.99725 1.00000</code></pre>
<pre class="r"><code>x_pca$rotation</code></pre>
<pre><code>##                PC1        PC2         PC3          PC4         PC5
## duracao -0.2478093 -0.5427337  0.25508083 -0.022880586  0.06238973
## nmoda   -0.2086872 -0.5815919  0.06605807  0.111931814  0.54715426
## volume  -0.3946802 -0.2965938  0.11920411  0.024446559 -0.80044844
## inercia -0.1966569 -0.1933099 -0.93770175 -0.169647198 -0.01961605
## moda    -0.4129991  0.2517535 -0.01369989  0.533407465  0.09932880
## media   -0.4267455  0.2631534  0.01070654 -0.003772862  0.14048445
## pico    -0.4057479  0.2143878  0.18851863 -0.782874738  0.14488542
## mediana -0.4281150  0.2515207 -0.03513275  0.245233214  0.07094631
##                 PC6          PC7         PC8
## duracao -0.15842994  0.725185516 -0.15347425
## nmoda    0.14315979 -0.516057049  0.12296633
## volume   0.07532313 -0.307250629  0.02565466
## inercia -0.08069840  0.091015866 -0.02667747
## moda    -0.67128726 -0.106825497 -0.09714031
## media    0.48212058 -0.008611709 -0.70445679
## pico    -0.28200152 -0.107278505  0.17014429
## mediana  0.42382510  0.286547949  0.65215827</code></pre>
<p>É interessante, em momento de exercicio, comparar o obtido através do algoritmo e o resultado da função <code>prcomp</code>.</p>
<p>É possível perceber, também, que com as três componentes principais podemos explicar cerca de 90% da variância dos dados, reduzindo de forma significativa o numéro de dimensões do nosso problema. Vamos, enfim, explorar a projeção das nossas componentes principais.</p>
<pre class="r"><code>factoextra::fviz_pca_biplot(x_pca, repel = FALSE)</code></pre>
<p><img src="/post/2019-05-21-introdução-ao-pc-parte-1_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Com o gráfico acima verificamos a direção de alguma das variáveis e como os dados se comportam após em função dos dois primeiros componentes gerados pela PCA. Observamos também que duração e nmoda estão bem correlacionados, assim como moda media, pico e mediana estão entre sí.</p>
<p>É pertinente para avaliarmos, também, se a relação entre as variáveis, tendo como base o fenômeno real, se mantem nesta projeção criada.</p>
<p>Podemos, ver também como acontece a projeção, tendo em vista as classificações dos usos domésticos de água:</p>
<pre class="r"><code>factoextra::fviz_pca_ind(x_pca,
             label = &quot;none&quot;, # hide individual labels
             habillage = dados$categoria, # color by groups
             addEllipses = TRUE # Concentration ellipses
             )</code></pre>
<p><img src="/post/2019-05-21-introdução-ao-pc-parte-1_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Ao observar, este plot, pode-se perceber que há uma certa definição dos grupos, sendo possível, com métodos como o <code>knn</code> treinar um modelo para determinar qual a categoria de uma nova observação a partir das componentes principais, nas quais a correlação entre as variáveis tende a ser nula.</p>
<p>Por fim, o PCA também pode ser utilizado para indicar possíveis <code>outliers</code> através do <code>Q contribution</code>. Deve-se, neste momento, realizar um pequeno esforço de abstração para entender que, num caso multivariado, há dois principais tipos de outliers. O primeiro diz respeito a valores aberrantes das variáveis, fora do range considerado aceitável para esta.</p>
<p>O segundo, e mais interessante no caso do PCA, versa sobre a quebra da correlação, ou seja, mesmo que os dados estejam dentro dos limites aceitáveis, uma dada observação nao respeita a correlação existente entre as variáveis.</p>
<pre class="r"><code>p &lt;- fviz_pca_ind(x_pca, addEllipses = TRUE, habillage = dados$categoria, ellipse.level=0.95, geom =                           c(&quot;text&quot;,&quot;point&quot;),
                  repel = FALSE) + xlim(-10, 15) + ylim (-10, 10) + labs(title =&quot;PCA&quot;, x = &quot;PC1&quot;, y = &quot;PC2&quot;)
p</code></pre>
<p><img src="/post/2019-05-21-introdução-ao-pc-parte-1_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Observando a elipse formada, inferimos a cerca dos <code>outliers</code>. Para selecionar e remover estes valores ditos aberrantes vamos utilizar as seguintes funções:</p>
<pre class="r"><code>outlier &lt;- which(p$data$contrib &gt; .5)  #podemos utilizar maiores ou menores valores para o Q.

outlier</code></pre>
<pre><code>## [1]   62  297  430  481  694 1345 1530</code></pre>
<pre class="r"><code>#Removendo os valores: 

data_pca &lt;- x_pca$x %&gt;% 
  as.tibble() %&gt;% 
  slice(-outlier)</code></pre>
<p>Em publicação posterior veremos como funciona o PCA em texto!</p>
</div>
</div>
</div>
