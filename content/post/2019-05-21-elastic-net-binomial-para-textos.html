---
title: Elastic-Net binomial para textos
author: Tarssio Barreto
date: '2019-05-21'
slug: elastic-net-binomial-para-textos
categories: []
tags: []
keywords:
  - tech
---



<div id="pacotes-que-serao-utilizados" class="section level2">
<h2>Pacotes que serão utilizados:</h2>
<pre class="r"><code>#install.packages(&quot;pacman&quot;)
library(pacman)


p_load(caret, tidyverse, factoextra, epubr, tm, lexiconPT, broom, tidytext, widyr, irlba, rsample, glmnet)</code></pre>
</div>
<div id="ajustes" class="section level2">
<h2>Ajustes</h2>
<p>Começamos, assim como as demais publicações, carregando os ebooks dos livros: “O Estrangeiro” e “Crime e Castigo”. Estamos trabalhando com eles há três publicações, qualquer coisa, olhem as antigas.</p>
<pre class="r"><code>x0 &lt;- epubr::epub(&quot;C:/Users/tarss/Desktop/SER/CURO_SER/O Estrangeiro - Albert Camus.epub&quot;)

x1 &lt;- epubr::epub(&quot;C:/Users/tarss/Desktop/SER/CURO_SER/Crime e Castigo - Fiódor Dostoiévski.epub&quot;)</code></pre>
</div>
<div id="tratando-os-textos" class="section level2">
<h2>Tratando os textos:</h2>
<p>Para os textos em questão vamos contar o numéro de vezes que cada palavra se repete por paragráfo já que nosso objetivo final é criar um modelo quais palavras são fortemente associadas aos parágrafos de cada um dos livros.</p>
<div id="o-estrangeiro" class="section level3">
<h3>O estrangeiro</h3>
<p>Vamos utilizar as funções do tidytext para ajustar os bancos de dados para aquilo que queremos. Removeremos também as stopwords.</p>
<pre class="r"><code># Removendo Stopwords
stop_words &lt;- stopwords(kind = &quot;pt&quot;) %&gt;% 
  as.tibble()

stop_words &lt;- rbind(stop_words, c(&quot;é&quot;))

colnames(stop_words)[1] &lt;- &quot;word&quot;

# ajustando estrangeiro

estrangeiro &lt;- x0$data[[1]]


estrangeiro_ &lt;- estrangeiro %&gt;%
  tidytext::unnest_tokens(paragraphs, text, token = &quot;paragraphs&quot;) %&gt;% 
  mutate(paragrafo = row_number()) %&gt;% 
  tidytext::unnest_tokens(word, paragraphs) %&gt;% 
  anti_join(stop_words, by = &quot;word&quot;)  %&gt;% 
  count(paragrafo, word, sort = TRUE) %&gt;% 
  mutate(book = &quot;estrangeiro&quot;)

head(estrangeiro_)</code></pre>
<pre><code>## # A tibble: 6 x 4
##   paragrafo word         n book       
##       &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;      
## 1       146 cão          8 estrangeiro
## 2       417 maria        6 estrangeiro
## 3       265 raimundo     5 estrangeiro
## 4       334 juiz         5 estrangeiro
## 5       362 cada         5 estrangeiro
## 6       424 raimundo     5 estrangeiro</code></pre>
<pre class="r"><code>id &lt;- max(estrangeiro_$paragrafo)</code></pre>
</div>
<div id="crime-e-castigo" class="section level3">
<h3>Crime e castigo</h3>
<pre class="r"><code>crime &lt;- x1$data[[1]]

crime_ &lt;- crime %&gt;%  
  tidytext::unnest_tokens(paragraphs, text, token = &quot;paragraphs&quot;) %&gt;% 
  mutate(paragrafo = row_number() + id) %&gt;%  # somamos ao id para termos continuidade no id dos paragrafos
  tidytext::unnest_tokens(word, paragraphs) %&gt;% 
  anti_join(stop_words, by = &quot;word&quot;)  %&gt;% 
  count(paragrafo, word, sort = TRUE) %&gt;% 
  mutate(book = &quot;crime&quot;) 

head(crime_)</code></pre>
<pre><code>## # A tibble: 6 x 4
##   paragrafo word          n book 
##       &lt;int&gt; &lt;chr&gt;     &lt;int&gt; &lt;chr&gt;
## 1      3352 ivánovna     40 crime
## 2      3332 ivánovna     33 crime
## 3      3782 senhor       32 crime
## 4       693 dúnia        29 crime
## 5      3352 catierina    24 crime
## 6       693 tudo         21 crime</code></pre>
</div>
</div>
<div id="nosso-banco-de-dados-final-fica" class="section level2">
<h2>Nosso banco de dados final fica:</h2>
<pre class="r"><code>df &lt;- rbind(estrangeiro_, crime_) 

head(df)</code></pre>
<pre><code>## # A tibble: 6 x 4
##   paragrafo word         n book       
##       &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;      
## 1       146 cão          8 estrangeiro
## 2       417 maria        6 estrangeiro
## 3       265 raimundo     5 estrangeiro
## 4       334 juiz         5 estrangeiro
## 5       362 cada         5 estrangeiro
## 6       424 raimundo     5 estrangeiro</code></pre>
<pre class="r"><code>range(df$paragrafo)</code></pre>
<pre><code>## [1]    1 4356</code></pre>
<pre class="r"><code>## Removendo nomes e outras stopwords que dificultam o entendimento da questão


nomes &lt;- c(&quot;raskólnikov&quot;, &quot;sônia&quot;, &quot;razumíkhin&quot;, &quot;ivánova&quot;, &quot;pietróvitch&quot;, &quot;n&quot;, 
           &quot;catierina&quot;, &quot;dúnia&quot;, &quot;svidrigáilov&quot;, &quot;porfiri&quot;, &quot;piotr&quot;, &quot;pulkhéria&quot;, 
           &quot;t&quot;, &quot;avdótia&quot;, &quot;ródia&quot;, &quot;románovna&quot;, &quot;rodíon&quot;, &quot;lújin&quot;, &quot;atieksándrovna&quot;,
           &quot;dúnietchka&quot;, &quot;zóssimov&quot;, &quot;zamiótov&quot;, &quot;marfa&quot;, &quot;sófia&quot;, &quot;semeónovna&quot;, &quot;nastácia&quot;,&quot;pietróvna&quot;, &quot;raskólnikovnn&quot;, &quot;amália&quot;, &quot;liebeziátnikov&quot;, &quot;raimundo&quot;, &quot;masson&quot;, &quot;u&quot;, &quot;perez&quot;, &quot;manuel&quot;, &quot;meursault&quot;, &quot;ivánovna&quot;, &quot;alieksándrovna&quot;, &quot;lisavieta&quot;,&quot;ei&quot;, &quot;capítulo&quot;,&quot;19&quot;, &quot;si&quot;, &quot;alguma&quot;, &quot;agora&quot;, &quot;jeito&quot;, &quot;instalamo&quot;, &quot;ora&quot;, &quot;algum&quot;, &quot;há&quot;,&quot;ainda&quot;, &quot;descemos&quot;,&quot;respondi&quot;,&quot;instante&quot;, &quot;bocadinho&quot;, &quot;soubera&quot;, &quot;ah&quot;, &quot;vou&quot;)


aux &lt;- df %&gt;%
  filter(!word %in% nomes) </code></pre>
</div>
<div id="treino-e-teste" class="section level2">
<h2>Treino e Teste</h2>
<p>Agora utilizaremos o pacote <code>rsample</code> para dividir nosso banco de dados final em treino e teste para que possamos realizar a modelagem e testar a sua capacidade de generalização.</p>
<pre class="r"><code>books_split &lt;- aux %&gt;%
  select(paragrafo, book) %&gt;%
  initial_split()

train_data &lt;- training(books_split)
test_data &lt;- testing(books_split)</code></pre>
</div>
<div id="matriz-esparsa" class="section level2">
<h2>Matriz Esparsa</h2>
<p>Como todas as postagens anteriores, criaremos, também, nossa matriz esparsa na qual as linhas são representadas pelos paragráfos, as colunas pelas palavras e são preenchidas pelo número de vezes que cada palavra aparece em cada um dos paragráfos.</p>
<pre class="r"><code>sparse_words &lt;- aux %&gt;%
  inner_join(train_data) %&gt;%
  cast_sparse(paragrafo, word, n)

word_rownames &lt;- as.integer(rownames(sparse_words))</code></pre>
</div>
<div id="modelando-os-dados-de-treino" class="section level2">
<h2>Modelando os dados de treino</h2>
<p>Carregando os dados de treino:</p>
<pre class="r"><code>model_df &lt;- train_data %&gt;% 
  filter(paragrafo %in% word_rownames) %&gt;% 
  distinct()</code></pre>
<p>##Criando uma variável que tem valores 0 e 1 para ser ou não o livro estrangeiro:</p>
<p>Neste caso, estamos criando nosso Y (variável binária que queremos modelar)</p>
<pre class="r"><code>is_camus &lt;- model_df$book == &quot;estrangeiro&quot;</code></pre>
</div>
<div id="elastic-net-binomial" class="section level2">
<h2>Elastic-net Binomial</h2>
<p>Vamos criar um modelo elastic-net cuja familia é binominal, desta forma realizamos algo muito parecido com a regressão logistica, mas com as vantagens de seleção de variáveis dada pelo elastic-net.</p>
<p>O Elastic Net é um modelo regularizado na qual há um sistema de penalidades que busca zerar os valores dos coeficientes de algumas variáveis que possuem pouca influência no modelo final.</p>
<pre class="r"><code>model &lt;- glmnet::cv.glmnet(sparse_words, is_camus,
                   family = &quot;binomial&quot;,
                   keep = TRUE)

summary(model)</code></pre>
<pre><code>##            Length Class  Mode     
## lambda         99 -none- numeric  
## cvm            99 -none- numeric  
## cvsd           99 -none- numeric  
## cvup           99 -none- numeric  
## cvlo           99 -none- numeric  
## nzero          99 -none- numeric  
## name            1 -none- character
## glmnet.fit     13 lognet list     
## fit.preval 423400 -none- numeric  
## foldid       4234 -none- numeric  
## lambda.min      1 -none- numeric  
## lambda.1se      1 -none- numeric</code></pre>
<p>Observamos, então, as palavras que mais contribuem para que dado paragráfo seja, ou não, do livro: O Estrangeiro.</p>
<p>Como palavras que tem maior probabilidade de pertencer a um paragráfo do livro Estrangeiro temos: <code>aborrecia</code>, <code>àrabe</code> e <code>alterada</code>. Todas referentes ao capítulo do assassinato do árabe na praia por parte do Mersault.</p>
<p>Por outro lado, as palavras com as menores probabilidades são: <code>senhor</code>, <code>gritou</code> e <code>pronunciou</code>. A palavra senhor é um tratamento MUITO utilizado no livro, principalmente, por uma questão de sentimento de inferioridade que o personagem de Crime e Castigo tem. Gritou, por sua vez, é uma palavra muito marcante da cena na qual este personagem assassina a machadadas uma senhora de idade.</p>
<pre class="r"><code>coefs &lt;- model$glmnet.fit %&gt;%
  tidy() %&gt;%
  filter(lambda == model$lambda.1se)


coefs %&gt;%
  group_by(estimate &gt; 0) %&gt;%
  top_n(10, abs(estimate)) %&gt;%
  ungroup() %&gt;%
  ggplot(aes(fct_reorder(term, estimate), estimate, fill = estimate &gt; 0)) +
  geom_col(alpha = 0.8, show.legend = FALSE) +
  coord_flip() +
  labs(
    x = NULL,
    title = &quot;Coefficients that increase/decrease probability the most&quot;
  ) +
  theme_minimal()</code></pre>
<p><img src="/post/2019-05-21-elastic-net-binomial-para-textos_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
</div>
<div id="testando-e-validando" class="section level2">
<h2>Testando e Validando</h2>
<p>Para validar um modelo, devemos ver o quão bem este é capaz de generalizar a predição para os valores de teste. Pegaremos nosso conjunto de teste, retornaremos o intercepto e os valores estimados e aplicaremos isto nos dados de teste para retornar a probabilidade de determinado paragráfo pertencer ao livro do Albert Camus.</p>
<pre class="r"><code># Encontrando o intercepto


intercept &lt;- coefs %&gt;%
  filter(term == &quot;(Intercept)&quot;) %&gt;%
  pull(estimate)

# Realizando a classificação, ou seja, qual a probabilidade de tal paragráfo, do grupo de teste, ser do livro &quot;O Estrangeiro&quot;

classifications &lt;- aux %&gt;%
  inner_join(test_data) %&gt;%
  inner_join(coefs, by = c(&quot;word&quot; = &quot;term&quot;)) %&gt;%
  group_by(paragrafo) %&gt;%
  summarize(score = sum(estimate)) %&gt;%
  mutate(probability = plogis(intercept + score))  # Retornar a probabilidade 

head(classifications)</code></pre>
<pre><code>## # A tibble: 6 x 3
##   paragrafo  score probability
##       &lt;int&gt;  &lt;dbl&gt;       &lt;dbl&gt;
## 1         3  8.46        0.997
## 2         6  8.95        0.998
## 3         7 10.2         0.999
## 4         8  0.802       0.131
## 5         9 20.0         1.000
## 6        10 13.5         1.000</code></pre>
</div>
<div id="juntando-os-bancos-de-dados-de-classificacao-e-teste" class="section level2">
<h2>Juntando os bancos de dados de classificação e teste:</h2>
<p>Vamos separar as classificações dadas as observações de teste e escolheremos 0.5 como threshold da classicação. Este passo será fundamental para posterior criação da matriz de confusão.</p>
<pre class="r"><code># Testando os resultados

test_df &lt;- test_data %&gt;% 
  filter(paragrafo %in% classifications$paragrafo) %&gt;% 
  distinct()


test &lt;- inner_join(classifications,test_df) %&gt;% 
  mutate(book = as.factor(book))

### Escolhendo 0.5 como threshold para classificação:

test &lt;- test %&gt;%
  mutate(
    prediction = case_when(
      probability &gt; 0.5 ~ &quot;estrangeiro&quot;,
      TRUE ~ &quot;crime&quot;
    ),
    prediction = as.factor(prediction))</code></pre>
</div>
<div id="resultado-final" class="section level2">
<h2>Resultado Final</h2>
<p>Temos um modelo de alta acurácia, boa sensitividade e sensibilidade, mesmo não sendo balanceado. Claro, que são dois livros distintos, em contextos distintos, mas é uma aplicação bastante interessante e que abre possibilidade para outras.</p>
<pre class="r"><code>caret::confusionMatrix(test$prediction, test$book)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##              Reference
## Prediction    crime estrangeiro
##   crime        1870          38
##   estrangeiro   267         421
##                                           
##                Accuracy : 0.8825          
##                  95% CI : (0.8695, 0.8947)
##     No Information Rate : 0.8232          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.6625          
##                                           
##  Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
##                                           
##             Sensitivity : 0.8751          
##             Specificity : 0.9172          
##          Pos Pred Value : 0.9801          
##          Neg Pred Value : 0.6119          
##              Prevalence : 0.8232          
##          Detection Rate : 0.7203          
##    Detection Prevalence : 0.7350          
##       Balanced Accuracy : 0.8961          
##                                           
##        &#39;Positive&#39; Class : crime           
## </code></pre>
</div>
