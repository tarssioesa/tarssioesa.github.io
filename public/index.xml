<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dad2s</title>
    <link>/</link>
    <description>Recent content on Dad2s</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-BR</language>
    <lastBuildDate>Tue, 21 May 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Elastic-Net binomial para textos</title>
      <link>/2019/05/elastic-net-binomial-para-textos/</link>
      <pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/elastic-net-binomial-para-textos/</guid>
      <description>Pacotes que serão utilizados:#install.packages(&amp;quot;pacman&amp;quot;)library(pacman)p_load(caret, tidyverse, factoextra, epubr, tm, lexiconPT, broom, tidytext, widyr, irlba, rsample, glmnet)AjustesComeçamos, assim como as demais publicações, carregando os ebooks dos livros: “O Estrangeiro” e “Crime e Castigo”. Estamos trabalhando com eles há três publicações, qualquer coisa, olhem as antigas.
x0 &amp;lt;- epubr::epub(&amp;quot;C:/Users/tarss/Desktop/SER/CURO_SER/O Estrangeiro - Albert Camus.epub&amp;quot;)x1 &amp;lt;- epubr::epub(&amp;quot;C:/Users/tarss/Desktop/SER/CURO_SER/Crime e Castigo - Fiódor Dostoiévski.epub&amp;quot;)Tratando os textos:Para os textos em questão vamos contar o numéro de vezes que cada palavra se repete por paragráfo já que nosso objetivo final é criar um modelo quais palavras são fortemente associadas aos parágrafos de cada um dos livros.</description>
    </item>
    
    <item>
      <title>Introdução ao PC: Parte 1.</title>
      <link>/2019/05/introdu%C3%A7%C3%A3o-ao-pc-parte-1/</link>
      <pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/introdu%C3%A7%C3%A3o-ao-pc-parte-1/</guid>
      <description>PCADe forma muito simples, o PCA tem as seguintes objetivos:
Reduzir a dimensão dos dados em análise, visando eliminar sobreposições, a partir da combinação linear das variáveis originais.
Geometricamente, o objetivo do PCA é rotacionar o eixo de um espaço com p dimensões para uma nova posição, na qual os PCs são ordenados pela variância e a covariância entre cada par dos novos eixos é 0.
Esta técnica é comumente utilizada para visualização dos dados, regressão (PCR, PLS) e estudo de padrões (inclusive em imagens e textos).</description>
    </item>
    
    <item>
      <title>Introdução ao PCA: Parte 2</title>
      <link>/2019/05/introdu%C3%A7%C3%A3o-ao-pca-parte-2/</link>
      <pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/introdu%C3%A7%C3%A3o-ao-pca-parte-2/</guid>
      <description>


</description>
    </item>
    
    <item>
      <title>T-SNE para textos.</title>
      <link>/2019/05/t-sne-para-textos/</link>
      <pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/t-sne-para-textos/</guid>
      <description>Pacotes que serão utilizados:#install.packages(&amp;quot;pacman&amp;quot;)library(pacman)p_load(caret, tidyverse, factoextra, epubr, tm, lexiconPT, broom, tidytext, widyr, irlba, Rtsne,plotly)t-SNEo t-SNE é um algoritmo de aprendizado de máquina para visualização desenvolvido por Laurens van der Maaten e Geoffrey Hinton. Esta técnica de redução de dimensionalidade não linear é bem pertinente para a transformação de dados em alta dimensionalidade para dados em duas ou três dimensões.</description>
    </item>
    
    <item>
      <title>Validação Cruzada</title>
      <link>/2019/05/valida%C3%A7%C3%A3o-cruzada/</link>
      <pubDate>Tue, 21 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/05/valida%C3%A7%C3%A3o-cruzada/</guid>
      <description>ObjetivoEsta pequena apresentação tem como objetivo demonstrar o funcionamento de métodos de validação cruzada utilizando o algoritmo KNN. A validação cruzada é uma técnica bastante interessante para verificar a capacidade de generalização de determinado modelo ou para identificar a melhor parametrização para este.
Para isto usaremos o pacote caret que nos possibilita criar uma estrutura base para aplicação de algoritmos de aprendizado de máquinas.
Neste pacote, a modelagem ocorre em “camadas”, ou seja, configuramos uma camada de entrada de dados, outra camada para pré-processamento de dados e outra para a validação cruzada.</description>
    </item>
    
  </channel>
</rss>