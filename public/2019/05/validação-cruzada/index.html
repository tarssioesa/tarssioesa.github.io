<!DOCTYPE html>
<html lang="pt-BR">
  <head>
    
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.55.6 with theme Tranquilpeak 0.4.3-SNAPSHOT">
<meta name="author" content="Tarssio Barreto">
<meta name="keywords" content="tech">
<meta name="description" content="ObjetivoEsta pequena apresentação tem como objetivo demonstrar o funcionamento de métodos de validação cruzada utilizando o algoritmo KNN. A validação cruzada é uma técnica bastante interessante para verificar a capacidade de generalização de determinado modelo ou para identificar a melhor parametrização para este.
Para isto usaremos o pacote caret que nos possibilita criar uma estrutura base para aplicação de algoritmos de aprendizado de máquinas.
Neste pacote, a modelagem ocorre em “camadas”, ou seja, configuramos uma camada de entrada de dados, outra camada para pré-processamento de dados e outra para a validação cruzada.">


<meta property="og:description" content="ObjetivoEsta pequena apresentação tem como objetivo demonstrar o funcionamento de métodos de validação cruzada utilizando o algoritmo KNN. A validação cruzada é uma técnica bastante interessante para verificar a capacidade de generalização de determinado modelo ou para identificar a melhor parametrização para este.
Para isto usaremos o pacote caret que nos possibilita criar uma estrutura base para aplicação de algoritmos de aprendizado de máquinas.
Neste pacote, a modelagem ocorre em “camadas”, ou seja, configuramos uma camada de entrada de dados, outra camada para pré-processamento de dados e outra para a validação cruzada.">
<meta property="og:type" content="article">
<meta property="og:title" content="Validação Cruzada">
<meta name="twitter:title" content="Validação Cruzada">
<meta property="og:url" content="/2019/05/valida%C3%A7%C3%A3o-cruzada/">
<meta property="twitter:url" content="/2019/05/valida%C3%A7%C3%A3o-cruzada/">
<meta property="og:site_name" content="Dad2s">
<meta property="og:description" content="ObjetivoEsta pequena apresentação tem como objetivo demonstrar o funcionamento de métodos de validação cruzada utilizando o algoritmo KNN. A validação cruzada é uma técnica bastante interessante para verificar a capacidade de generalização de determinado modelo ou para identificar a melhor parametrização para este.
Para isto usaremos o pacote caret que nos possibilita criar uma estrutura base para aplicação de algoritmos de aprendizado de máquinas.
Neste pacote, a modelagem ocorre em “camadas”, ou seja, configuramos uma camada de entrada de dados, outra camada para pré-processamento de dados e outra para a validação cruzada.">
<meta name="twitter:description" content="ObjetivoEsta pequena apresentação tem como objetivo demonstrar o funcionamento de métodos de validação cruzada utilizando o algoritmo KNN. A validação cruzada é uma técnica bastante interessante para verificar a capacidade de generalização de determinado modelo ou para identificar a melhor parametrização para este.
Para isto usaremos o pacote caret que nos possibilita criar uma estrutura base para aplicação de algoritmos de aprendizado de máquinas.
Neste pacote, a modelagem ocorre em “camadas”, ou seja, configuramos uma camada de entrada de dados, outra camada para pré-processamento de dados e outra para a validação cruzada.">
<meta property="og:locale" content="pt-BR">

  
    <meta property="article:published_time" content="2019-05-21T00:00:00">
  
  
    <meta property="article:modified_time" content="2019-05-21T00:00:00">
  
  
  
  


<meta name="twitter:card" content="summary">

  <meta name="twitter:site" content="@okrabarreto">


  <meta name="twitter:creator" content="@okrabarreto">










  <meta property="og:image" content="https://www.gravatar.com/avatar/2cbd1c8403ef218d99b08637747420f8?s=640">
  <meta property="twitter:image" content="https://www.gravatar.com/avatar/2cbd1c8403ef218d99b08637747420f8?s=640">


    <title>Validação Cruzada</title>

    <link rel="icon" href="/favicon.png">
    

    

    <link rel="canonical" href="/2019/05/valida%C3%A7%C3%A3o-cruzada/">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.css" integrity="sha256-vuXZ9LGmmwtjqFX1F+EKin1ThZMub58gKULUyf0qECk=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" integrity="sha256-SEa4XYAHihTcEP1f5gARTB2K26Uk8PsndQYHQC1f4jU=" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="/css/style-nnm2spxvve8onlujjlegkkytaehyadd4ksxc1hyzzq9a2wvtrgbljqyulomn.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="4">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">Dad2s</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="https://www.gravatar.com/avatar/2cbd1c8403ef218d99b08637747420f8?s=90" alt="" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="4">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="/#about">
          <img class="sidebar-profile-picture" src="https://www.gravatar.com/avatar/2cbd1c8403ef218d99b08637747420f8?s=110" alt="" />
        </a>
        <h4 class="sidebar-profile-name">Tarssio Barreto</h4>
        
          <h5 class="sidebar-profile-bio">Um entusiasta da ciência de dados. Tenho me aventurado em tutorias, consultorias, aulas particulares, estágio em docência e por aí vai. Este blog tem como objetivo divulgar e compartilhar um pouco do que tenho feito!</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Arquivos</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">Profile</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/tarssioesa">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="4"
        class="
               hasCoverMetaIn
               ">
        <article class="post" itemscope itemType="http://schema.org/BlogPosting">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title" itemprop="headline">
      Validação Cruzada
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time itemprop="datePublished" datetime="2019-05-21T00:00:00Z">
        
   21, 2019

      </time>
    
    
  </div>

</div>
          
          <div class="post-content markdown" itemprop="articleBody">
            <div class="main-content-wrap">
              


<div style="text-align: justify">




<div id="objetivo" class="section level2">
<h2>Objetivo</h2>
<p>Esta pequena apresentação tem como objetivo demonstrar o funcionamento de métodos de validação cruzada utilizando o algoritmo KNN. A validação cruzada é uma técnica bastante interessante para verificar a capacidade de generalização de determinado modelo ou para identificar a melhor parametrização para este.</p>
<p>Para isto usaremos o pacote <code>caret</code> que nos possibilita criar uma estrutura base para aplicação de algoritmos de aprendizado de máquinas.</p>
<p>Neste pacote, a modelagem ocorre em “camadas”, ou seja, configuramos uma camada de entrada de dados, outra camada para pré-processamento de dados e outra para a validação cruzada. É possível, também, realizar o afunilamento dos parâmetros a serem determinados, conseguindo maior precisão na determinação destes e no resultado final, porém não será o foco deste breve documento.</p>
<p>Nesta demonstração será utilizado os dados referentes a classificação do uso doméstico de água. Para tornar mais didático será utilizado, apenas, as categórias referentes ao uso de chuveiro, bacia e torneira interna.</p>
<p>Serão, também, simulados, a partir destes dados, três diferentes tipos de bancos de dados:</p>
<ol style="list-style-type: lower-alpha">
<li><p>Neste primeiro, haverá uma amostra composta de mil unidades de cada uma das categorias;</p></li>
<li><p>Neste, a amostra é de 10 observações de cada uma destas;</p></li>
<li><p>No último, haverá 50 observações de chuveiro e bacia, porém, apenas 20 de torneira interna.</p></li>
</ol>
<p>Queremos, por fim, comparar a performace dos métodos de validação cruzada para cada um destes. Os métodos utilizados serão o de <code>Boostrap</code>, <code>k folds</code> e <code>Repeated k folds</code>.</p>
<p>O <code>Boostrap</code> é um método baseado, na sua forma mais simplória, na reamostragem com reposição das obsevações encontradas no banco de dados. Sendo, particularmente, útil na estimativa da distribuição empírica de estatísticas e na estimativa de intervalo de confiança para os estimadores.</p>
<p>No <code>k folds</code> dividimos nossa base de dados em k partes, quando temos k igual ao número de observações obtemos o leave-one-out.</p>
<p>Quando realizamos o <code>Repetead k folds</code> repetimos o <code>k folds</code> n vezes, sendo que há o embaralhamento das amostras dos dados antes de cada repetição.</p>
<p>Para aprofundamento teórico sugere-se a leitura de : “An Introduction to Statiscal Learning” : Gareth James, Daniela Witten, Trevor Hastie e Robert Tibshirani.</p>
<pre class="r"><code># Bibliotecas

require(caret)</code></pre>
<pre><code>## Carregando pacotes exigidos: caret</code></pre>
<pre><code>## Carregando pacotes exigidos: lattice</code></pre>
<pre><code>## Carregando pacotes exigidos: ggplot2</code></pre>
<pre class="r"><code>require(tidyverse)</code></pre>
<pre><code>## Carregando pacotes exigidos: tidyverse</code></pre>
<pre><code>## -- Attaching packages ------------------------------------------------------------------------ tidyverse 1.2.1 --</code></pre>
<pre><code>## v tibble  2.1.1       v purrr   0.3.2  
## v tidyr   0.8.3       v dplyr   0.8.0.1
## v readr   1.3.1       v stringr 1.4.0  
## v tibble  2.1.1       v forcats 0.4.0</code></pre>
<pre><code>## -- Conflicts --------------------------------------------------------------------------- tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
## x purrr::lift()   masks caret::lift()</code></pre>
<pre class="r"><code>require(gridExtra)</code></pre>
<pre><code>## Carregando pacotes exigidos: gridExtra</code></pre>
<pre><code>## 
## Attaching package: &#39;gridExtra&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     combine</code></pre>
<div id="carregando-dados" class="section level3">
<h3>Carregando dados</h3>
<pre class="r"><code>data &lt;- load(&quot;C:/Users/tarss/Desktop/LIME_AGUA/cross-validation/cross/data_041218_1138.RData&quot;)</code></pre>
</div>
<div id="exemplo-a" class="section level3">
<h3>Exemplo A</h3>
<div id="obtendo-a-amostragem-desejada" class="section level4">
<h4>Obtendo a amostragem desejada:</h4>
<pre class="r"><code># Criando amostragem

set.seed(1)

dados &lt;- features_atual %&gt;% 
  filter(categoria %in% c(&quot;Bacia&quot;, &quot;Chuveiro&quot;, &quot;Torneira Interna&quot;)) %&gt;% 
  filter(casa == &quot;B&quot;)

dados$categoria &lt;- fct_drop(dados$categoria)  # Removendo as categórias não utilizadas

sample &lt;- dados %&gt;%
  group_by(categoria) %&gt;%
  sample_n(1000) %&gt;%  # Escolhendo 1000 observações de cada
  select(-c(10:18)) %&gt;% 
  na.omit()

head(sample)</code></pre>
<pre><code>## # A tibble: 6 x 9
## # Groups:   categoria [1]
##   categoria duracao nmoda volume inercia  moda media  pico mediana
##   &lt;fct&gt;       &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
## 1 Bacia          40     3  0.700   3      1.20  1.05  1.20    1.20
## 2 Bacia         110    10  5.30   10      3     2.89  3       3   
## 3 Bacia         160    12  4.40    4.33   1.80  1.65  2.40    1.80
## 4 Bacia          60     3  7.80    2      8.60  7.80  9.20    8.60
## 5 Bacia         120     7  6.10    1.4    3.60  3.05  3.60    3.60
## 6 Bacia         140     5  9.90    0.556  4.80  4.24  4.80    4.20</code></pre>
</div>
<div id="criando-o-grupo-de-treino-e-de-teste" class="section level4">
<h4>Criando o grupo de treino e de teste:</h4>
<pre class="r"><code># Definindo Split

split=0.80

trainIndex &lt;- createDataPartition(sample$categoria, p=split, list=FALSE)

# Separando 

data_train &lt;- sample[ trainIndex,]

data_test &lt;- sample[-trainIndex,]</code></pre>
</div>
<div id="com-bootstrap" class="section level4">
<h4>Com Bootstrap</h4>
<pre class="r"><code>model &lt;- train(categoria ~ ., 
               data = data_train,
               method = &quot;knn&quot;,
               preProcess = c(&quot;center&quot;, &quot;scale&quot;),
               tuneLength = 10, 
               trControl = trainControl(method = &quot;boot&quot;))

model</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 2400 samples
##    8 predictor
##    3 classes: &#39;Bacia&#39;, &#39;Torneira Interna&#39;, &#39;Chuveiro&#39; 
## 
## Pre-processing: centered (8), scaled (8) 
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 2400, 2400, 2400, 2400, 2400, 2400, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa    
##    5  0.6335375  0.4504252
##    7  0.6402937  0.4605450
##    9  0.6445510  0.4670280
##   11  0.6473185  0.4712062
##   13  0.6490409  0.4737846
##   15  0.6506494  0.4762175
##   17  0.6487977  0.4734362
##   19  0.6490465  0.4738308
##   21  0.6501826  0.4755473
##   23  0.6516640  0.4777978
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 23.</code></pre>
<pre class="r"><code># Armazenando o número ótimo de vizinhos

k1 &lt;- model$finalModel$k</code></pre>
<p>Obtido, então, a melhor estimativa de vizinhos próximos com o bootstrap, será avaliada a acurácia deste modelo aplicado ao teste:</p>
<pre class="r"><code># Realizando a predição para o teste

predictions &lt;- predict(model, data_test)

# Observando os resultados

confusionMatrix(predictions, data_test$categoria) </code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##                   Reference
## Prediction         Bacia Torneira Interna Chuveiro
##   Bacia              145               22       84
##   Torneira Interna    12              144        8
##   Chuveiro            43               34      108
## 
## Overall Statistics
##                                           
##                Accuracy : 0.6617          
##                  95% CI : (0.6222, 0.6995)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.4925          
##                                           
##  Mcnemar&#39;s Test P-Value : 4.585e-07       
## 
## Statistics by Class:
## 
##                      Class: Bacia Class: Torneira Interna Class: Chuveiro
## Sensitivity                0.7250                  0.7200          0.5400
## Specificity                0.7350                  0.9500          0.8075
## Pos Pred Value             0.5777                  0.8780          0.5838
## Neg Pred Value             0.8424                  0.8716          0.7783
## Prevalence                 0.3333                  0.3333          0.3333
## Detection Rate             0.2417                  0.2400          0.1800
## Detection Prevalence       0.4183                  0.2733          0.3083
## Balanced Accuracy          0.7300                  0.8350          0.6738</code></pre>
<pre class="r"><code>aux &lt;- confusionMatrix(predictions, data_test$categoria)

# Armazenando para futuras comparações

acc1 &lt;- aux$overall[1]</code></pre>
</div>
<div id="k-fold" class="section level4">
<h4>k-fold</h4>
<pre class="r"><code>model2 &lt;- train(categoria ~ ., 
      data = data_train,
      method = &quot;knn&quot;,
      preProcess = c(&quot;center&quot;, &quot;scale&quot;),
      tuneLength = 10, 
      trControl = trainControl(method=&quot;cv&quot;, number=10))

model2</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 2400 samples
##    8 predictor
##    3 classes: &#39;Bacia&#39;, &#39;Torneira Interna&#39;, &#39;Chuveiro&#39; 
## 
## Pre-processing: centered (8), scaled (8) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 2160, 2160, 2160, 2160, 2160, 2160, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa   
##    5  0.6500000  0.475000
##    7  0.6570833  0.485625
##    9  0.6525000  0.478750
##   11  0.6529167  0.479375
##   13  0.6608333  0.491250
##   15  0.6650000  0.497500
##   17  0.6654167  0.498125
##   19  0.6633333  0.495000
##   21  0.6658333  0.498750
##   23  0.6687500  0.503125
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 23.</code></pre>
<pre class="r"><code># Armazenando o número ótimo de vizinhos

k2 &lt;- model2$finalModel$k</code></pre>
<p>Observando, então, os resultados para o conjunto de dados do teste:</p>
<pre class="r"><code># Realizando a predição para os dados de teste

predictions &lt;- predict(model2, data_test)

# Observando os resultados

confusionMatrix(predictions, data_test$categoria) </code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##                   Reference
## Prediction         Bacia Torneira Interna Chuveiro
##   Bacia              148               22       83
##   Torneira Interna    12              145        8
##   Chuveiro            40               33      109
## 
## Overall Statistics
##                                           
##                Accuracy : 0.67            
##                  95% CI : (0.6308, 0.7075)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.505           
##                                           
##  Mcnemar&#39;s Test P-Value : 2.898e-07       
## 
## Statistics by Class:
## 
##                      Class: Bacia Class: Torneira Interna Class: Chuveiro
## Sensitivity                0.7400                  0.7250          0.5450
## Specificity                0.7375                  0.9500          0.8175
## Pos Pred Value             0.5850                  0.8788          0.5989
## Neg Pred Value             0.8501                  0.8736          0.7823
## Prevalence                 0.3333                  0.3333          0.3333
## Detection Rate             0.2467                  0.2417          0.1817
## Detection Prevalence       0.4217                  0.2750          0.3033
## Balanced Accuracy          0.7388                  0.8375          0.6813</code></pre>
<pre class="r"><code>aux &lt;- confusionMatrix(predictions, data_test$categoria)

# Armazenando 

acc2 &lt;- aux$overall[1]</code></pre>
</div>
<div id="repeated-k-fold-cross-validation" class="section level4">
<h4>Repeated k-fold Cross Validation</h4>
<p>Repetiremos o mesmo feito para o “repeated k-fold”</p>
<pre class="r"><code>model3 &lt;- train(categoria ~ ., 
               data = data_train,
               method = &quot;knn&quot;,
               preProcess = c(&quot;center&quot;, &quot;scale&quot;),
               tuneLength = 10, 
               trControl = trainControl(method=&quot;repeatedcv&quot;, number=10, repeats=10))


model3</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 2400 samples
##    8 predictor
##    3 classes: &#39;Bacia&#39;, &#39;Torneira Interna&#39;, &#39;Chuveiro&#39; 
## 
## Pre-processing: centered (8), scaled (8) 
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 2160, 2160, 2160, 2160, 2160, 2160, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa   
##    5  0.6555833  0.483375
##    7  0.6570000  0.485500
##    9  0.6565833  0.484875
##   11  0.6595833  0.489375
##   13  0.6600000  0.490000
##   15  0.6612500  0.491875
##   17  0.6631667  0.494750
##   19  0.6650000  0.497500
##   21  0.6644167  0.496625
##   23  0.6624167  0.493625
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 19.</code></pre>
<pre class="r"><code>k3 &lt;- model3$finalModel$k</code></pre>
<p>Observando, então, os resultados para o grupo de testes:</p>
<pre class="r"><code># Predição

predictions &lt;- predict(model3, data_test)

# Resultados

confusionMatrix(predictions, data_test$categoria) </code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##                   Reference
## Prediction         Bacia Torneira Interna Chuveiro
##   Bacia              152               18       80
##   Torneira Interna    11              148        8
##   Chuveiro            37               34      112
## 
## Overall Statistics
##                                           
##                Accuracy : 0.6867          
##                  95% CI : (0.6479, 0.7236)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.53            
##                                           
##  Mcnemar&#39;s Test P-Value : 2.42e-07        
## 
## Statistics by Class:
## 
##                      Class: Bacia Class: Torneira Interna Class: Chuveiro
## Sensitivity                0.7600                  0.7400          0.5600
## Specificity                0.7550                  0.9525          0.8225
## Pos Pred Value             0.6080                  0.8862          0.6120
## Neg Pred Value             0.8629                  0.8799          0.7890
## Prevalence                 0.3333                  0.3333          0.3333
## Detection Rate             0.2533                  0.2467          0.1867
## Detection Prevalence       0.4167                  0.2783          0.3050
## Balanced Accuracy          0.7575                  0.8462          0.6913</code></pre>
<pre class="r"><code>aux &lt;- confusionMatrix(predictions, data_test$categoria)

acc3 &lt;- aux$overall[1]</code></pre>
</div>
<div id="comparacoes" class="section level4">
<h4>Comparações</h4>
<p>A primeira comparação, será aquela de vizinhos próximos:</p>
<pre class="r"><code>metodos &lt;- c(&quot;bootstrap&quot;, &quot;k-folds&quot;, &quot;rep. k-folds&quot;)

k &lt;- cbind(k1,k2,k3)

colnames(k) &lt;- metodos

k</code></pre>
<pre><code>##      bootstrap k-folds rep. k-folds
## [1,]        23      23           19</code></pre>
<p>Outra comparação, de grande importância, versa sobre a distribuição da acurácia (boxplot) de cada um dos métodos:</p>
<pre class="r"><code>boxplot(model[[&quot;resample&quot;]][[&quot;Accuracy&quot;]], model2[[&quot;resample&quot;]][[&quot;Accuracy&quot;]], model3[[&quot;resample&quot;]][[&quot;Accuracy&quot;]])</code></pre>
<p><img src="/post/2019-05-21-validação-cruzada_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Por fim, comparando a acurácia do teste:</p>
<pre class="r"><code>acc &lt;- cbind(acc1, acc2, acc3)

colnames(acc) &lt;- metodos

acc</code></pre>
<pre><code>##          bootstrap k-folds rep. k-folds
## Accuracy 0.6616667    0.67    0.6866667</code></pre>
<p>É interessante observar que o modelo de repetidos k-folds possui melhores resultados quanto a acurácia do teste e tem o menor número ótimos de vizinhos, sendo um modelo mais simples quando comparado aos demais.</p>
<p>Pontua-se, também, que o bootstrap é o modelo com os piores valores de acurácia, quando se observa os conjuntos de validação cruzada, enquanto que os repetidos k-folds apresentam grande variabilidade, mas bom resultado mediano.</p>
</div>
</div>
</div>
<div id="exemplo-b" class="section level1">
<h1>Exemplo B</h1>
<p>Neste exemplo há menos dados, 10 de cada uma dos métodos, observaremos, como os métodos de validação cruzadas reagirão.</p>
<div id="ajustando-a-amostragem" class="section level3">
<h3>Ajustando a amostragem:</h3>
<pre class="r"><code>set.seed(1)

dados &lt;- features_atual %&gt;% 
  filter(categoria %in% c(&quot;Bacia&quot;, &quot;Chuveiro&quot;, &quot;Torneira Interna&quot; )) %&gt;% 
  filter(casa == &quot;B&quot;)

dados$categoria &lt;- fct_drop(dados$categoria)

sample &lt;- dados %&gt;%
  group_by(categoria) %&gt;%
  sample_n(10) %&gt;% 
  select(-c(10:18))


# Definindo Split

split=0.80

trainIndex &lt;- createDataPartition(sample$categoria, p=split, list=FALSE)

data_train &lt;- sample[ trainIndex,]

data_test &lt;- sample[-trainIndex,]</code></pre>
</div>
<div id="com-bootstrap-1" class="section level3">
<h3>Com Bootstrap</h3>
<pre class="r"><code>model &lt;- train(categoria ~ ., 
               data = data_train,
               method = &quot;knn&quot;,
               preProcess = c(&quot;center&quot;, &quot;scale&quot;),
               tuneLength = 10, 
               trControl = trainControl(method = &quot;boot&quot;))

model</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 24 samples
##  8 predictor
##  3 classes: &#39;Bacia&#39;, &#39;Torneira Interna&#39;, &#39;Chuveiro&#39; 
## 
## Pre-processing: centered (8), scaled (8) 
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 24, 24, 24, 24, 24, 24, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa        
##    5  0.4185960   0.1689475688
##    7  0.3981284   0.1694012245
##    9  0.3903478   0.1617269789
##   11  0.3464747   0.1032896027
##   13  0.3018687   0.0473766703
##   15  0.2991212   0.0621640749
##   17  0.2704214   0.0384434124
##   19  0.2320058  -0.0001058204
##   21  0.2308615  -0.0027628721
##   23  0.2176118  -0.0273536608
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 5.</code></pre>
<pre class="r"><code># Armazenando o número ótimo de vizinhos

k1 &lt;- model$finalModel$k</code></pre>
<p>Obtido, então, a melhor estimativa de vizinhos próximos com o bootstrap, para o exemplo B, será avaliada a acurácia deste modelo aplicado ao teste:</p>
<pre class="r"><code># Realizando a predição para o teste

predictions &lt;- predict(model, data_test)

# Observando os resultados

confusionMatrix(predictions, data_test$categoria) </code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##                   Reference
## Prediction         Bacia Torneira Interna Chuveiro
##   Bacia                1                0        2
##   Torneira Interna     0                2        0
##   Chuveiro             1                0        0
## 
## Overall Statistics
##                                           
##                Accuracy : 0.5             
##                  95% CI : (0.1181, 0.8819)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : 0.3196          
##                                           
##                   Kappa : 0.25            
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: Bacia Class: Torneira Interna Class: Chuveiro
## Sensitivity                0.5000                  1.0000          0.0000
## Specificity                0.5000                  1.0000          0.7500
## Pos Pred Value             0.3333                  1.0000          0.0000
## Neg Pred Value             0.6667                  1.0000          0.6000
## Prevalence                 0.3333                  0.3333          0.3333
## Detection Rate             0.1667                  0.3333          0.0000
## Detection Prevalence       0.5000                  0.3333          0.1667
## Balanced Accuracy          0.5000                  1.0000          0.3750</code></pre>
<pre class="r"><code>aux &lt;- confusionMatrix(predictions, data_test$categoria)

# Armazenando para futuras comparações

acc1 &lt;- aux$overall[1]</code></pre>
</div>
<div id="k-fold-1" class="section level3">
<h3>k-fold</h3>
<pre class="r"><code>model2 &lt;- train(categoria ~ ., 
      data = data_train,
      method = &quot;knn&quot;,
      preProcess = c(&quot;center&quot;, &quot;scale&quot;),
      tuneLength = 10, 
      trControl = trainControl(method=&quot;cv&quot;, number=10))

model2</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 24 samples
##  8 predictor
##  3 classes: &#39;Bacia&#39;, &#39;Torneira Interna&#39;, &#39;Chuveiro&#39; 
## 
## Pre-processing: centered (8), scaled (8) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 21, 23, 22, 21, 21, 22, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa      
##    5  0.5833333   0.25925926
##    7  0.4833333   0.14814815
##    9  0.4500000   0.09259259
##   11  0.4666667   0.14814815
##   13  0.3500000  -0.09259259
##   15  0.4166667   0.07407407
##   17  0.3666667   0.03703704
##   19  0.3666667   0.03703704
##   21  0.3833333   0.14814815
##   23  0.1333333  -0.05000000
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 5.</code></pre>
<pre class="r"><code># Armazenando o número ótimo de vizinhos

k2 &lt;- model2$finalModel$k</code></pre>
<p>Observando, então, os resultados para o conjunto de dados do teste:</p>
<pre class="r"><code># Realizando a predição para os dados de teste

predictions &lt;- predict(model2, data_test)

# Observando os resultados

confusionMatrix(predictions, data_test$categoria) </code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##                   Reference
## Prediction         Bacia Torneira Interna Chuveiro
##   Bacia                1                0        2
##   Torneira Interna     1                2        0
##   Chuveiro             0                0        0
## 
## Overall Statistics
##                                           
##                Accuracy : 0.5             
##                  95% CI : (0.1181, 0.8819)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : 0.3196          
##                                           
##                   Kappa : 0.25            
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: Bacia Class: Torneira Interna Class: Chuveiro
## Sensitivity                0.5000                  1.0000          0.0000
## Specificity                0.5000                  0.7500          1.0000
## Pos Pred Value             0.3333                  0.6667             NaN
## Neg Pred Value             0.6667                  1.0000          0.6667
## Prevalence                 0.3333                  0.3333          0.3333
## Detection Rate             0.1667                  0.3333          0.0000
## Detection Prevalence       0.5000                  0.5000          0.0000
## Balanced Accuracy          0.5000                  0.8750          0.5000</code></pre>
<pre class="r"><code>aux &lt;- confusionMatrix(predictions, data_test$categoria)

# Armazenando 

acc2 &lt;- aux$overall[1]</code></pre>
</div>
<div id="repeated-k-fold-cross-validation-1" class="section level3">
<h3>Repeated k-fold Cross Validation</h3>
<p>Repetiremos o mesmo feito para o “repeated k-fold”</p>
<pre class="r"><code>model3 &lt;- train(categoria ~ ., 
               data = data_train,
               method = &quot;knn&quot;,
               preProcess = c(&quot;center&quot;, &quot;scale&quot;),
               tuneLength = 10, 
               trControl = trainControl(method=&quot;repeatedcv&quot;, number=10, repeats=10))


model3</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 24 samples
##  8 predictor
##  3 classes: &#39;Bacia&#39;, &#39;Torneira Interna&#39;, &#39;Chuveiro&#39; 
## 
## Pre-processing: centered (8), scaled (8) 
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 22, 21, 22, 22, 22, 22, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa       
##    5  0.5505051   0.310283688
##    7  0.5488215   0.289007092
##    9  0.3771044   0.088541667
##   11  0.3501684   0.064236111
##   13  0.3367003   0.032646048
##   15  0.3451178   0.036458333
##   17  0.3636364   0.064236111
##   19  0.2811448  -0.003401361
##   21  0.2659933   0.073129252
##   23  0.1784512   0.015151515
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 5.</code></pre>
<pre class="r"><code>k3 &lt;- model3$finalModel$k</code></pre>
<p>Observando, então, os resultados para o grupo de testes:</p>
<pre class="r"><code># Predição

predictions &lt;- predict(model3, data_test)

# Resultados

confusionMatrix(predictions, data_test$categoria) </code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##                   Reference
## Prediction         Bacia Torneira Interna Chuveiro
##   Bacia                1                0        1
##   Torneira Interna     0                2        0
##   Chuveiro             1                0        1
## 
## Overall Statistics
##                                           
##                Accuracy : 0.6667          
##                  95% CI : (0.2228, 0.9567)
##     No Information Rate : 0.3333          
##     P-Value [Acc &gt; NIR] : 0.1001          
##                                           
##                   Kappa : 0.5             
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: Bacia Class: Torneira Interna Class: Chuveiro
## Sensitivity                0.5000                  1.0000          0.5000
## Specificity                0.7500                  1.0000          0.7500
## Pos Pred Value             0.5000                  1.0000          0.5000
## Neg Pred Value             0.7500                  1.0000          0.7500
## Prevalence                 0.3333                  0.3333          0.3333
## Detection Rate             0.1667                  0.3333          0.1667
## Detection Prevalence       0.3333                  0.3333          0.3333
## Balanced Accuracy          0.6250                  1.0000          0.6250</code></pre>
<pre class="r"><code>aux &lt;- confusionMatrix(predictions, data_test$categoria)

acc3 &lt;- aux$overall[1]</code></pre>
</div>
<div id="comparacoes-1" class="section level3">
<h3>Comparações</h3>
<div id="comparando-o-k-otimo" class="section level4">
<h4>Comparando o “k” ótimo:</h4>
<p>A primeira comparação, será aquela de vizinhos próximos:</p>
<pre class="r"><code>metodos &lt;- c(&quot;bootstrap&quot;, &quot;k-folds&quot;, &quot;rep. k-folds&quot;)

k &lt;- cbind(k1,k2,k3)

colnames(k) &lt;- metodos

k</code></pre>
<pre><code>##      bootstrap k-folds rep. k-folds
## [1,]         5       5            5</code></pre>
<p>Outra comparação, de grande importância, versa sobre a distribuição da acurácia (boxplot) de cada um dos métodos:</p>
<pre class="r"><code>boxplot(model[[&quot;resample&quot;]][[&quot;Accuracy&quot;]], model2[[&quot;resample&quot;]][[&quot;Accuracy&quot;]], model3[[&quot;resample&quot;]][[&quot;Accuracy&quot;]])</code></pre>
<p><img src="/post/2019-05-21-validação-cruzada_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>Por fim, comparando a acurácia do teste:</p>
<pre class="r"><code>acc &lt;- cbind(acc1, acc2, acc3)

colnames(acc) &lt;- metodos

acc</code></pre>
<pre><code>##          bootstrap k-folds rep. k-folds
## Accuracy       0.5     0.5    0.6666667</code></pre>
<p>Uma vez reduzido o número de observações, também são diminuido o número de vizinhos próximos considerados no knn. Outra questão visível diz respeito a distribuição da acurácia nos dados de treino que é igual para o k-fold e para os repetidos k-folds, consequência, também, da baixa quantidade de observações.</p>
<p>Porém, novamente, os repetidos k-folds demonstraram melhores resultados frente aos dados de treino. Enquanto que os resultados do boostrap e do k-folds são parecidos.</p>
</div>
</div>
<div id="exemplo-c" class="section level3">
<h3>Exemplo C</h3>
</div>
</div>
<div id="criando-amostragem" class="section level1">
<h1>Criando amostragem</h1>
<pre class="r"><code>set.seed(1)

dados &lt;- features_atual %&gt;% 
  filter(categoria %in% c(&quot;Bacia&quot;, &quot;Chuveiro&quot;)) %&gt;% 
  filter(casa == &quot;B&quot;)


sample &lt;- dados %&gt;%
  group_by(categoria) %&gt;%
  sample_n(50)


dados2 &lt;- features_atual %&gt;% 
  filter(categoria %in% c(&quot;Torneira Interna&quot;)) %&gt;% 
  filter(casa == &quot;B&quot;)

sample2 &lt;- dados2 %&gt;%
  sample_n(10) 

sample_final &lt;- bind_rows(sample, sample2) %&gt;% 
  select(-c(10:18))

sample_final$categoria &lt;- fct_drop(sample_final$categoria)</code></pre>
<pre class="r"><code># Definindo Split

split=0.80

trainIndex &lt;- createDataPartition(sample_final$categoria, p=split, list=FALSE)

data_train &lt;- sample_final[trainIndex,]

data_test &lt;- sample_final[-trainIndex,]</code></pre>
<div id="por-boostrap" class="section level3">
<h3>Por Boostrap</h3>
<pre class="r"><code>model &lt;- train(categoria ~ ., 
               data = data_train,
               method = &quot;knn&quot;,
               preProcess = c(&quot;center&quot;, &quot;scale&quot;),
               tuneLength = 10, 
               trControl = trainControl(method = &quot;boot&quot;))

model</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 88 samples
##  8 predictor
##  3 classes: &#39;Bacia&#39;, &#39;Torneira Interna&#39;, &#39;Chuveiro&#39; 
## 
## Pre-processing: centered (8), scaled (8) 
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 88, 88, 88, 88, 88, 88, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa     
##    5  0.5390613  0.18943653
##    7  0.5194965  0.14943477
##    9  0.5032134  0.11701582
##   11  0.4687869  0.05644428
##   13  0.4807345  0.07379152
##   15  0.4765920  0.06828667
##   17  0.4806196  0.07477825
##   19  0.4637459  0.04845997
##   21  0.4525194  0.02780356
##   23  0.4584021  0.03508098
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 5.</code></pre>
<pre class="r"><code># Armazenando o número ótimo de vizinhos

k1 &lt;- model$finalModel$k</code></pre>
<p>Obtido, então, a melhor estimativa de vizinhos próximos com o bootstrap, para o exemplo B, será avaliada a acurácia deste modelo aplicado ao teste:</p>
<pre class="r"><code># Realizando a predição para o teste

predictions &lt;- predict(model, data_test)

# Observando os resultados

confusionMatrix(predictions, data_test$categoria) </code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##                   Reference
## Prediction         Bacia Torneira Interna Chuveiro
##   Bacia                7                0        3
##   Torneira Interna     0                0        0
##   Chuveiro             3                2        7
## 
## Overall Statistics
##                                          
##                Accuracy : 0.6364         
##                  95% CI : (0.4066, 0.828)
##     No Information Rate : 0.4545         
##     P-Value [Acc &gt; NIR] : 0.06715        
##                                          
##                   Kappa : 0.3333         
##                                          
##  Mcnemar&#39;s Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: Bacia Class: Torneira Interna Class: Chuveiro
## Sensitivity                0.7000                 0.00000          0.7000
## Specificity                0.7500                 1.00000          0.5833
## Pos Pred Value             0.7000                     NaN          0.5833
## Neg Pred Value             0.7500                 0.90909          0.7000
## Prevalence                 0.4545                 0.09091          0.4545
## Detection Rate             0.3182                 0.00000          0.3182
## Detection Prevalence       0.4545                 0.00000          0.5455
## Balanced Accuracy          0.7250                 0.50000          0.6417</code></pre>
<pre class="r"><code>aux &lt;- confusionMatrix(predictions, data_test$categoria)

# Armazenando para futuras comparações

acc1 &lt;- aux$overall[1]</code></pre>
</div>
<div id="k-fold-2" class="section level3">
<h3>k-fold</h3>
<pre class="r"><code>model2 &lt;- train(categoria ~ ., 
      data = data_train,
      method = &quot;knn&quot;,
      preProcess = c(&quot;center&quot;, &quot;scale&quot;),
      tuneLength = 10, 
      trControl = trainControl(method=&quot;cv&quot;, number=10))

model2</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 88 samples
##  8 predictor
##  3 classes: &#39;Bacia&#39;, &#39;Torneira Interna&#39;, &#39;Chuveiro&#39; 
## 
## Pre-processing: centered (8), scaled (8) 
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 79, 79, 79, 79, 79, 79, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa    
##    5  0.6263889  0.3317647
##    7  0.6388889  0.3412500
##    9  0.6055556  0.2862500
##   11  0.6027778  0.2700000
##   13  0.5680556  0.2050000
##   15  0.5805556  0.2300000
##   17  0.5819444  0.2350000
##   19  0.5625000  0.2050000
##   21  0.5625000  0.2050000
##   23  0.5263889  0.1350000
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 7.</code></pre>
<pre class="r"><code># Armazenando o número ótimo de vizinhos

k2 &lt;- model2$finalModel$k</code></pre>
<p>Observando, então, os resultados para o conjunto de dados do teste:</p>
<pre class="r"><code># Realizando a predição para os dados de teste

predictions &lt;- predict(model2, data_test)

# Observando os resultados

confusionMatrix(predictions, data_test$categoria) </code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##                   Reference
## Prediction         Bacia Torneira Interna Chuveiro
##   Bacia                6                0        6
##   Torneira Interna     0                0        0
##   Chuveiro             4                2        4
## 
## Overall Statistics
##                                           
##                Accuracy : 0.4545          
##                  95% CI : (0.2439, 0.6779)
##     No Information Rate : 0.4545          
##     P-Value [Acc &gt; NIR] : 0.582           
##                                           
##                   Kappa : 0               
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: Bacia Class: Torneira Interna Class: Chuveiro
## Sensitivity                0.6000                 0.00000          0.4000
## Specificity                0.5000                 1.00000          0.5000
## Pos Pred Value             0.5000                     NaN          0.4000
## Neg Pred Value             0.6000                 0.90909          0.5000
## Prevalence                 0.4545                 0.09091          0.4545
## Detection Rate             0.2727                 0.00000          0.1818
## Detection Prevalence       0.5455                 0.00000          0.4545
## Balanced Accuracy          0.5500                 0.50000          0.4500</code></pre>
<pre class="r"><code>aux &lt;- confusionMatrix(predictions, data_test$categoria)

# Armazenando 

acc2 &lt;- aux$overall[1]</code></pre>
</div>
<div id="repeated-k-fold-cross-validation-2" class="section level3">
<h3>Repeated k-fold Cross Validation</h3>
<p>Repetiremos o mesmo feito para o “repeated k-fold”</p>
<pre class="r"><code>model3 &lt;- train(categoria ~ ., 
               data = data_train,
               method = &quot;knn&quot;,
               preProcess = c(&quot;center&quot;, &quot;scale&quot;),
               tuneLength = 10, 
               trControl = trainControl(method=&quot;repeatedcv&quot;, number=10, repeats=10))


model3</code></pre>
<pre><code>## k-Nearest Neighbors 
## 
## 88 samples
##  8 predictor
##  3 classes: &#39;Bacia&#39;, &#39;Torneira Interna&#39;, &#39;Chuveiro&#39; 
## 
## Pre-processing: centered (8), scaled (8) 
## Resampling: Cross-Validated (10 fold, repeated 10 times) 
## Summary of sample sizes: 80, 79, 79, 79, 79, 80, ... 
## Resampling results across tuning parameters:
## 
##   k   Accuracy   Kappa    
##    5  0.6254167  0.3216765
##    7  0.6026389  0.2721667
##    9  0.5993056  0.2670000
##   11  0.5625000  0.1961111
##   13  0.5752778  0.2190000
##   15  0.5694444  0.2080000
##   17  0.5486111  0.1710000
##   19  0.5256944  0.1285000
##   21  0.5245833  0.1265000
##   23  0.5162500  0.1105000
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was k = 5.</code></pre>
<pre class="r"><code>k3 &lt;- model3$finalModel$k</code></pre>
<p>Observando, então, os resultados para o grupo de testes:</p>
<pre class="r"><code># Predição

predictions &lt;- predict(model3, data_test)

# Resultados

confusionMatrix(predictions, data_test$categoria) </code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##                   Reference
## Prediction         Bacia Torneira Interna Chuveiro
##   Bacia                7                0        3
##   Torneira Interna     0                0        0
##   Chuveiro             3                2        7
## 
## Overall Statistics
##                                          
##                Accuracy : 0.6364         
##                  95% CI : (0.4066, 0.828)
##     No Information Rate : 0.4545         
##     P-Value [Acc &gt; NIR] : 0.06715        
##                                          
##                   Kappa : 0.3333         
##                                          
##  Mcnemar&#39;s Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: Bacia Class: Torneira Interna Class: Chuveiro
## Sensitivity                0.7000                 0.00000          0.7000
## Specificity                0.7500                 1.00000          0.5833
## Pos Pred Value             0.7000                     NaN          0.5833
## Neg Pred Value             0.7500                 0.90909          0.7000
## Prevalence                 0.4545                 0.09091          0.4545
## Detection Rate             0.3182                 0.00000          0.3182
## Detection Prevalence       0.4545                 0.00000          0.5455
## Balanced Accuracy          0.7250                 0.50000          0.6417</code></pre>
<pre class="r"><code>aux &lt;- confusionMatrix(predictions, data_test$categoria)

acc3 &lt;- aux$overall[1]</code></pre>
</div>
<div id="comparacoes-2" class="section level3">
<h3>Comparações</h3>
<div id="comparando-o-k-otimo-1" class="section level4">
<h4>Comparando o “k” ótimo:</h4>
<p>A primeira comparação, será aquela de vizinhos próximos:</p>
<pre class="r"><code>metodos &lt;- c(&quot;bootstrap&quot;, &quot;k-folds&quot;, &quot;rep. k-folds&quot;)

k &lt;- cbind(k1,k2,k3)

colnames(k) &lt;- metodos

k</code></pre>
<pre><code>##      bootstrap k-folds rep. k-folds
## [1,]         5       7            5</code></pre>
<p>Outra comparação, de grande importância, versa sobre a distribuição da acurácia (boxplot) de cada um dos métodos:</p>
<pre class="r"><code>boxplot(model[[&quot;resample&quot;]][[&quot;Accuracy&quot;]], model2[[&quot;resample&quot;]][[&quot;Accuracy&quot;]], model3[[&quot;resample&quot;]][[&quot;Accuracy&quot;]])</code></pre>
<p><img src="/post/2019-05-21-validação-cruzada_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>Por fim, comparando a acurácia do teste:</p>
<pre class="r"><code>acc &lt;- cbind(acc1, acc2, acc3)

colnames(acc) &lt;- metodos

acc</code></pre>
<pre><code>##          bootstrap   k-folds rep. k-folds
## Accuracy 0.6363636 0.4545455    0.6363636</code></pre>
<p>Neste último caso, a despeito de uma boa diferença entre a distribuição das acurácias para os métodos de bootstrap e repetidos k-folds, se obteve o mesmo resultado para os dados de treino.</p>
<p>O exposto nesta breve postagem diz respeito a uma questão prática de como realizar e por que realizar a validação cruzada ao se aplicar um modelo, não supri a necessidade de entender os métodos.</p>
</div>
</div>
</div>

              
            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
            
            <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/05/introdu%C3%A7%C3%A3o-ao-pc-parte-1/" data-tooltip="Introdução ao PC: Parte 1.">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml"></span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <span class="hide-xs hide-sm text-small icon-mr"></span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2019/05/valida%C3%A7%C3%A3o-cruzada/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2019/05/valida%C3%A7%C3%A3o-cruzada/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2019/05/valida%C3%A7%C3%A3o-cruzada/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

            
              
                <div id="disqus_thread">
  <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
              
            
          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2019 Tarssio Barreto. 
  </span>
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="4">
        <div class="post-actions-wrap">
  
      <nav >
        <ul class="post-actions post-action-nav">
          
            <li class="post-action">
              
                <a class="post-action-btn btn btn--default tooltip--top" href="/2019/05/introdu%C3%A7%C3%A3o-ao-pc-parte-1/" data-tooltip="Introdução ao PC: Parte 1.">
              
                  <i class="fa fa-angle-left"></i>
                  <span class="hide-xs hide-sm text-small icon-ml"></span>
                </a>
            </li>
            <li class="post-action">
              
                <a class="post-action-btn btn btn--disabled">
              
                  <span class="hide-xs hide-sm text-small icon-mr"></span>
                  <i class="fa fa-angle-right"></i>
                </a>
            </li>
          
        </ul>
      </nav>
    <ul class="post-actions post-action-share" >
      
        <li class="post-action hide-lg hide-md hide-sm">
          <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions">
            <i class="fa fa-share-alt"></i>
          </a>
        </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://www.facebook.com/sharer/sharer.php?u=/2019/05/valida%C3%A7%C3%A3o-cruzada/">
              <i class="fa fa-facebook-official"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=/2019/05/valida%C3%A7%C3%A3o-cruzada/">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
        
          <li class="post-action hide-xs">
            <a class="post-action-btn btn btn--default" target="new" href="https://plus.google.com/share?url=/2019/05/valida%C3%A7%C3%A3o-cruzada/">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        
      
      
        <li class="post-action">
          <a class="post-action-btn btn btn--default" href="#disqus_thread">
            <i class="fa fa-comment-o"></i>
          </a>
        </li>
      
      <li class="post-action">
        
          <a class="post-action-btn btn btn--default" href="#">
        
          <i class="fa fa-list"></i>
        </a>
      </li>
    </ul>
  
</div>

      </div>
      <div id="share-options-bar" class="share-options-bar" data-behavior="4">
  <i id="btn-close-shareoptions" class="fa fa-close"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://www.facebook.com/sharer/sharer.php?u=%2F2019%2F05%2Fvalida%25C3%25A7%25C3%25A3o-cruzada%2F">
          <i class="fa fa-facebook-official"></i><span>%!(EXTRA string=Facebook)</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=%2F2019%2F05%2Fvalida%25C3%25A7%25C3%25A3o-cruzada%2F">
          <i class="fa fa-twitter"></i><span>%!(EXTRA string=Twitter)</span>
        </a>
      </li>
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://plus.google.com/share?url=%2F2019%2F05%2Fvalida%25C3%25A7%25C3%25A3o-cruzada%2F">
          <i class="fa fa-google-plus"></i><span>%!(EXTRA string=Google&#43;)</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://www.gravatar.com/avatar/2cbd1c8403ef218d99b08637747420f8?s=110" alt="" />
    
    <h4 id="about-card-name">Tarssio Barreto</h4>
    
      <div id="about-card-bio">Um entusiasta da ciência de dados. Tenho me aventurado em tutorias, consultorias, aulas particulares, estágio em docência e por aí vai. Este blog tem como objetivo divulgar e compartilhar um pouco do que tenho feito!</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Doutorando
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Salvador
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" rel="noopener" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center"></div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/05/introdu%C3%A7%C3%A3o-ao-pc-parte-1/">
                <h3 class="media-heading">Introdução ao PC: Parte 1.</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  May 5, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">PCADe forma muito simples, o PCA tem as seguintes objetivos:
Reduzir a dimensão dos dados em análise, visando eliminar sobreposições, a partir da combinação linear das variáveis originais.
Geometricamente, o objetivo do PCA é rotacionar o eixo de um espaço com p dimensões para uma nova posição, na qual os PCs são ordenados pela variância e a covariância entre cada par dos novos eixos é 0.
Esta técnica é comumente utilizada para visualização dos dados, regressão (PCR, PLS) e estudo de padrões (inclusive em imagens e textos).</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/05/valida%C3%A7%C3%A3o-cruzada/">
                <h3 class="media-heading">Validação Cruzada</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  May 5, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">ObjetivoEsta pequena apresentação tem como objetivo demonstrar o funcionamento de métodos de validação cruzada utilizando o algoritmo KNN. A validação cruzada é uma técnica bastante interessante para verificar a capacidade de generalização de determinado modelo ou para identificar a melhor parametrização para este.
Para isto usaremos o pacote caret que nos possibilita criar uma estrutura base para aplicação de algoritmos de aprendizado de máquinas.
Neste pacote, a modelagem ocorre em “camadas”, ou seja, configuramos uma camada de entrada de dados, outra camada para pré-processamento de dados e outra para a validação cruzada.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero=""
         data-message-one=""
         data-message-other="">
         2 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('/images/cover.jpg');"></div>
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.2.4/jquery.min.js" integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44=" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.7/js/jquery.fancybox.min.js" integrity="sha256-GEAnjcTqVP+vBp3SSc8bEDQqvWAZMiHyUSIorrWwH50=" crossorigin="anonymous"></script>


<script src="/js/script-qi9wbxp2ya2j6p7wx1i6tgavftewndznf4v0hy2gvivk1rxgc3lm7njqb6bz.min.js"></script>


<script lang="javascript">
window.onload = updateMinWidth;
window.onresize = updateMinWidth;
document.getElementById("sidebar").addEventListener("transitionend", updateMinWidth);
function updateMinWidth() {
  var sidebar = document.getElementById("sidebar");
  var main = document.getElementById("main");
  main.style.minWidth = "";
  var w1 = getComputedStyle(main).getPropertyValue("min-width");
  var w2 = getComputedStyle(sidebar).getPropertyValue("width");
  var w3 = getComputedStyle(sidebar).getPropertyValue("left");
  main.style.minWidth = `calc(${w1} - ${w2} - ${w3})`;
}
</script>

<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>


  
    
      <script>
        var disqus_config = function () {
          this.page.url = '\/2019\/05\/valida%C3%A7%C3%A3o-cruzada\/';
          
            this.page.identifier = '\/2019\/05\/valida%C3%A7%C3%A3o-cruzada\/'
          
        };
        (function() {
          
          
          if (window.location.hostname == "localhost") {
            return;
          }
          var d = document, s = d.createElement('script');
          var disqus_shortname = 'hugo-tranquilpeak-theme';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);
        })();
      </script>
    
  




    
  </body>
</html>

